**WanGP** support many diferent models. Some of them are just better. You will find below a selection.

Hit any link below to load that model in the Video Generator instantly.

| Role | Model | Why pick it |
| --- | --- | --- |
| Video editing, face injection, spatial & temporal outpainting | [Wan 2.1 VACE](modeltype:vace_14B) | Load a control video, mask the regions you want to affect using Matanyone, and let the model replace faces, patch damaged areas, or extend the scene outside the original frame. If you are looking for an accelerated version of Vace usable out of the box, just try [Vace Fusionix](modeltype:vace_14B_fusionix). |
| Identity-preserving face replacement | [Lynx](modeltype:lynx), [Vace Lynx](modeltype:vace_lynx_14B) | Optimized to keep facial identity even when the hair style, clothes, or lighting change. Feed reference portraits, adjust the Lynx weight sliders, and blend with a VACE pass when you need both background cleanup and face swaps. |
| Motion transfer & performer replacement | [Wan 2.2 Animate](modeltype:animate) | Built for body/facial motion transfers: capture a pose/control video, extract masks with Mat Anyone, and it will replace or animate the target performer. Includes relighting, maskless mode (faster but less precise), and WanGP-exclusive outpainting so new characters stay anchored in the scene. |
| Multi-speaker lip-sync & dialogue | [MultiTalk](modeltype:multitalk),  [InfiniteTalk](modeltype:infinitetalk) | Drop one or two voice tracks, assign speakers, and the model handles lip-sync, gestures, and camera moves. InfiniteTalk mode chains sliding windows so very long monologues/conversations remain coherent. |
| High-fidelity image editing & inpainting | [Qwen Image Edit](modeltype:qwen_image_edit_plus_20B) | Generates or edits high-resolution stills with multi-subject control and long text captions. Works best at 720p, supports brush-based inpainting/outpainting, and has Lightning LoRAs (4-step/8-step) for faster iterations—ideal for prepping key frames before video runs. |
| Storyboarding with first / last frames | [Wan 2.2 i2v](modeltype:i2v_2_2) + [Qwen Image Edit](modeltype:qwen_image_edit_plus_20B) | Supply “first frame” and “last frame” stills for every beat using Qwen, then have Wan generate the motion bridge between them (similar to Nano Banana + Kling loops). Recycle the previous last frame as the next first frame to build entire scenes. As an alternative to i2v use, [InfiniteTalk](modeltype:infinitetalk) (without a speaker) as it offers fluid scene transitions. |
| Fast stylized skits | [Ovi 1.1](modeltype:ovi_1_1_10s) | Very fun and fast at generating videos with talking characters. Two presets (5 s / 10 s) that run on 6–8 GB VRAM and respond well to FastWan accelerators (~10× faster).  |
| Cinematic, long text-to-video | [LTX Video 0.98](modeltype:ltxv_distilled) | Generates 720p clips up to 1 minute. Supports IC-LoRAs (pose, depth, canny, detailer) so you can guide motion or add an internal upscaling pass without leaving WanGP. |
| Voice cloning / dubbing | [Chatterbox](modeltype:chatterbox) | Give it a short clean voice sample and it reproduces that voice (many languages) in 10–15 s clips. Save the WAV, drop it into MultiTalk/InfiniteTalk, and your avatars now speak with the cloned voice. |
